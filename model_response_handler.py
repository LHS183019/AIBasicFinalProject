from ui_manager import UIManager
from abc import ABC, abstractmethod

# TODO:
# 1. 处理多模态输出(图片、语音)
# 2. 完善GeminiModelResponseHandler(图片、语音)

class ResponseHandlerInterface(ABC):
    """Interface for handling model responses."""
    @abstractmethod
    def handle_text_response(self, response, UI:UIManager,show_reasoning:bool):
        """You should handle the streaming response from the ask_LLM func and make the UI update
        """
        pass

    @abstractmethod
    def handle_media_response(self, response, UI:UIManager):
        pass

        
class SiliconflowModelResponseHandler(ResponseHandlerInterface):
        
    def handle_text_response(self, response, UI:UIManager, show_reasoning:bool = True) -> None:
        """handling streaming response generated by the openAIChatCompletemen    

        Args:
            response : response returned by the llm.ask_LLM()
        """        
        UI.handle_signal("display_starts")
        for chunk in response:
            if not hasattr(chunk.choices[0].delta,"reasoning_content"):
                show_reasoning = False
            if not chunk.choices:
                continue
            if UI.paused_response_output:
                break
            if chunk.choices[0].delta.content:
                UI.display_text_output(chunk.choices[0].delta.content, reasoning=False)
            if show_reasoning and chunk.choices[0].delta.reasoning_content:
                UI.display_text_output(chunk.choices[0].delta.reasoning_content, reasoning=True)
        UI.handle_signal("display_ends")
        
    # TODO
    def handle_media_response(self, response, UI):
        pass
    
class GeminiModelResponseHandler(ResponseHandlerInterface):
    def handle_text_response(self, response, UI:UIManager, show_reasoning:bool = True) -> None:
        """handling streaming response generated by the openAIChatCompletemen    

        Args:
            response : response returned by the llm.ask_LLM()
        """        
        UI.handle_signal("display_starts")
        for chunk in response:
            if not hasattr(chunk.choices[0].delta,"reasoning_content"):
                show_reasoning = False
            if not chunk.choices:
                continue
            if UI.paused_response_output:
                break
            if chunk.choices[0].delta.content:
                UI.display_text_output(chunk.choices[0].delta.content, reasoning=False)
            if show_reasoning and chunk.choices[0].delta.reasoning_content:
                UI.display_text_output(chunk.choices[0].delta.reasoning_content, reasoning=True)
        UI.handle_signal("display_ends")
        
    # TODO
    def handle_media_response(self, response, UI):
        pass
    
